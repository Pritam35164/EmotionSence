{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663747bb-2ae0-4f53-b267-5258870ba925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Found 2880 audio files.\n",
      "Processed 200 files...\n",
      "Processed 400 files...\n",
      "Processed 600 files...\n",
      "Processed 800 files...\n",
      "Processed 1000 files...\n",
      "Processed 1200 files...\n",
      "Processed 1400 files...\n",
      "Processed 1600 files...\n",
      "Processed 1800 files...\n",
      "Processed 2000 files...\n",
      "Processed 2200 files...\n",
      "Processed 2400 files...\n",
      "Processed 2600 files...\n",
      "Processed 2800 files...\n",
      "‚úÖ Saved features to features_mfcc_delta.csv\n",
      "‚ö†Ô∏è Skipped 0 files due to errors or unknown labels.\n",
      "üéØ Original class distribution:\n",
      " label\n",
      "calm         384\n",
      "happy        384\n",
      "sad          384\n",
      "angry        384\n",
      "fearful      384\n",
      "disgust      384\n",
      "surprised    384\n",
      "neutral      192\n",
      "Name: count, dtype: int64\n",
      "üéØ Filtered class distribution:\n",
      " label\n",
      "calm         384\n",
      "happy        384\n",
      "sad          384\n",
      "angry        384\n",
      "fearful      384\n",
      "disgust      384\n",
      "surprised    384\n",
      "neutral      192\n",
      "Name: count, dtype: int64\n",
      "üöÄ Training generalized SVM model...\n",
      "‚úÖ Accuracy: 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.90      0.98      0.94        57\n",
      "        calm       0.86      0.89      0.88        57\n",
      "     disgust       0.80      0.84      0.82        58\n",
      "     fearful       0.92      0.93      0.92        58\n",
      "       happy       0.89      0.88      0.89        58\n",
      "     neutral       0.93      0.93      0.93        29\n",
      "         sad       0.94      0.77      0.85        57\n",
      "   surprised       0.97      0.97      0.97        58\n",
      "\n",
      "    accuracy                           0.90       432\n",
      "   macro avg       0.90      0.90      0.90       432\n",
      "weighted avg       0.90      0.90      0.90       432\n",
      "\n",
      "üîÑ Cross-val mean accuracy: 0.97\n",
      "üíæ Saved model bundle to generalized_emotion_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import streamlit as st\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "MODEL_FILE = \"generalized_emotion_model.joblib\"\n",
    "SESSION_LOG = \"session_log.csv\"\n",
    "RECORD_SECONDS_DEFAULT = 3\n",
    "SAMPLE_RATE = 22050  # Must match training SR\n",
    "N_MFCC = 40  # mfcc count used in training\n",
    "\n",
    "st.set_page_config(page_title=\"üéôÔ∏è Live Voice Emotion (Record/Upload)\", layout=\"centered\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load model bundle\n",
    "# ----------------------------\n",
    "@st.cache_resource\n",
    "def load_model(bundle_path=MODEL_FILE):\n",
    "    if not os.path.exists(bundle_path):\n",
    "        return None, None\n",
    "    bundle = joblib.load(bundle_path)\n",
    "    model = bundle.get(\"model\") if isinstance(bundle, dict) else bundle\n",
    "    label_encoder = bundle.get(\"label_encoder\") if isinstance(bundle, dict) else None\n",
    "    return model, label_encoder\n",
    "\n",
    "model, label_encoder = load_model()\n",
    "if model is None or label_encoder is None:\n",
    "    st.error(f\"Model bundle not found or invalid. Expected '{MODEL_FILE}' containing {{'model','label_encoder'}}.\")\n",
    "    st.stop()\n",
    "\n",
    "# ----------------------------\n",
    "# Emotion color gradients (card-style)\n",
    "# ----------------------------\n",
    "EMO_COLORS = {\n",
    "    \"calm\": (\"#a8dadc\", \"#457b9d\"),\n",
    "    \"happy\": (\"#fff3b0\", \"#ffb703\"),\n",
    "    \"sad\": (\"#d8c1f0\", \"#6a4c93\"),\n",
    "    \"angry\": (\"#ffd6d6\", \"#ff4d4d\"),\n",
    "    \"fearful\": (\"#ffd8b1\", \"#f07066\"),\n",
    "    \"disgust\": (\"#c7f9cc\", \"#2b9348\"),\n",
    "    \"surprised\": (\"#ffd6ff\", \"#ff61a6\"),\n",
    "    \"neutral\": (\"#e9ecef\", \"#6c757d\")\n",
    "}\n",
    "\n",
    "# Fallback color\n",
    "DEFAULT_GRADIENT = (\"#f6f6f6\", \"#d1d1d1\")\n",
    "\n",
    "# ----------------------------\n",
    "# Utility: feature extraction (MFCC + delta + delta-delta -> 120 features)\n",
    "# ----------------------------\n",
    "def extract_features(file_path, sr=SAMPLE_RATE, n_mfcc=N_MFCC):\n",
    "    y, sr = librosa.load(file_path, sr=sr, mono=True)\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    # Core MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "    # Delta and Delta-Delta\n",
    "    delta_mfcc = librosa.feature.delta(mfcc)\n",
    "    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "    delta_mean = np.mean(delta_mfcc, axis=1)\n",
    "    delta2_mean = np.mean(delta2_mfcc, axis=1)\n",
    "\n",
    "    features = np.hstack([mfcc_mean, delta_mean, delta2_mean])\n",
    "    return features.reshape(1, -1)\n",
    "\n",
    "# ----------------------------\n",
    "# Recording helper\n",
    "# ----------------------------\n",
    "def record_audio(duration=RECORD_SECONDS_DEFAULT, sr=SAMPLE_RATE):\n",
    "    st.info(f\"Recording for {duration} seconds... (make sure your microphone is enabled)\")\n",
    "    try:\n",
    "        recording = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=\"float32\")\n",
    "        sd.wait()\n",
    "    except Exception as e:\n",
    "        st.error(\"Recording failed: \" + str(e))\n",
    "        return None\n",
    "\n",
    "    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    sf.write(tmp.name, recording.flatten(), sr)\n",
    "    return tmp.name\n",
    "\n",
    "# ----------------------------\n",
    "# Session-state init (history)\n",
    "# ----------------------------\n",
    "if \"history_df\" not in st.session_state:\n",
    "    if os.path.exists(SESSION_LOG):\n",
    "        try:\n",
    "            st.session_state[\"history_df\"] = pd.read_csv(SESSION_LOG)\n",
    "        except Exception:\n",
    "            st.session_state[\"history_df\"] = pd.DataFrame()\n",
    "    else:\n",
    "        st.session_state[\"history_df\"] = pd.DataFrame()\n",
    "\n",
    "if \"current_session\" not in st.session_state:\n",
    "    st.session_state[\"current_session\"] = []\n",
    "\n",
    "# ----------------------------\n",
    "# Small helper: build gradient card HTML\n",
    "# ----------------------------\n",
    "def emotion_card_html(emotion, confidence, emoji=\"üéØ\"):\n",
    "    emo_lower = str(emotion).lower()\n",
    "    grad = EMO_COLORS.get(emo_lower, DEFAULT_GRADIENT)\n",
    "    color_from, color_to = grad\n",
    "    conf_pct = f\"{confidence*100:.1f}%\"\n",
    "    # Icon map (simple)\n",
    "    ICONS = {\n",
    "        \"calm\": \"üåä\",\n",
    "        \"happy\": \"üòÑ\",\n",
    "        \"sad\": \"üò¢\",\n",
    "        \"angry\": \"üò†\",\n",
    "        \"fearful\": \"üò®\",\n",
    "        \"disgust\": \"ü§¢\",\n",
    "        \"surprised\": \"üò≤\",\n",
    "        \"neutral\": \"üòê\"\n",
    "    }\n",
    "    icon = ICONS.get(emo_lower, \"üéØ\")\n",
    "    html = f\"\"\"\n",
    "    <div style=\"padding:16px;border-radius:14px;\n",
    "                background: linear-gradient(135deg, {color_from}, {color_to});\n",
    "                box-shadow: 0 6px 18px rgba(0,0,0,0.12);\n",
    "                color:#0b0b0b;\">\n",
    "      <div style=\"display:flex; align-items:center; gap:12px;\">\n",
    "        <div style=\"font-size:44px;\">{icon}</div>\n",
    "        <div>\n",
    "          <div style=\"font-size:20px; font-weight:700; letter-spacing:0.5px;\">{emotion.upper()}</div>\n",
    "          <div style=\"margin-top:6px; font-size:14px; opacity:0.95;\">Confidence: <strong>{conf_pct}</strong></div>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction + logging logic (shared for record/upload)\n",
    "# ----------------------------\n",
    "def predict_and_log(audio_path):\n",
    "    try:\n",
    "        feats = extract_features(audio_path)\n",
    "        probs = model.predict_proba(feats)[0]  # probabilities aligned with model.classes_\n",
    "        class_indices = model.classes_\n",
    "        # Map encoded class indices to string labels using label_encoder\n",
    "        labels = label_encoder.inverse_transform(class_indices.astype(int))\n",
    "        # Build prob dataframe in the correct order\n",
    "        prob_df = pd.DataFrame({\"emotion\": labels, \"probability\": probs})\n",
    "        # Top prediction\n",
    "        top_idx = int(np.argmax(probs))\n",
    "        top_label = labels[top_idx]\n",
    "        top_conf = float(probs[top_idx])\n",
    "\n",
    "        # Show card (HTML)\n",
    "        card_html = emotion_card_html(top_label, top_conf)\n",
    "        st.markdown(card_html, unsafe_allow_html=True)\n",
    "\n",
    "        # Show probability bar chart (matplotlib)\n",
    "        prob_df_sorted = prob_df.sort_values(\"probability\", ascending=False).reset_index(drop=True)\n",
    "        fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "        ax.barh(prob_df_sorted[\"emotion\"][::-1], prob_df_sorted[\"probability\"][::-1])\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xlabel(\"Probability\")\n",
    "        ax.set_title(\"Emotion probabilities\")\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Also show a neat table\n",
    "        prob_table = prob_df_sorted.copy()\n",
    "        prob_table[\"probability\"] = (prob_table[\"probability\"] * 100).map(lambda x: f\"{x:.1f}%\")\n",
    "        st.table(prob_table)\n",
    "\n",
    "        # Log row (timestamp, predicted, prob_<label>...)\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        log_row = {\"timestamp\": timestamp, \"predicted\": top_label}\n",
    "        for i, lab in enumerate(labels):\n",
    "            log_row[f\"prob_{lab}\"] = float(probs[i])\n",
    "\n",
    "        # Append to CSV\n",
    "        if os.path.exists(SESSION_LOG):\n",
    "            try:\n",
    "                existing = pd.read_csv(SESSION_LOG)\n",
    "                existing = pd.concat([existing, pd.DataFrame([log_row])], ignore_index=True)\n",
    "                existing.to_csv(SESSION_LOG, index=False)\n",
    "            except Exception:\n",
    "                pd.DataFrame([log_row]).to_csv(SESSION_LOG, index=False)\n",
    "        else:\n",
    "            pd.DataFrame([log_row]).to_csv(SESSION_LOG, index=False)\n",
    "\n",
    "        # Update session state (history df and current in-memory list)\n",
    "        if \"history_df\" not in st.session_state:\n",
    "            st.session_state[\"history_df\"] = pd.DataFrame([log_row])\n",
    "        else:\n",
    "            st.session_state[\"history_df\"] = pd.concat([st.session_state[\"history_df\"], pd.DataFrame([log_row])], ignore_index=True)\n",
    "        st.session_state[\"current_session\"].append(log_row)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(\"Prediction failed: \" + str(e))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        try:\n",
    "            os.remove(audio_path)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# ----------------------------\n",
    "# UI: Title + description\n",
    "# ----------------------------\n",
    "st.title(\"üéôÔ∏è Human Emotion Detection ‚Äî Record or Upload\")\n",
    "st.markdown(\n",
    "    \"Record a short audio clip or upload a WAV file. The app predicts emotion, shows a colored card with confidence, \"\n",
    "    \"probabilities, logs the session and updates the trend graph instantly.\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Input area: Record or Upload\n",
    "# ----------------------------\n",
    "st.subheader(\"Input Audio\")\n",
    "col1, col2 = st.columns(2)\n",
    "input_audio_path = None\n",
    "\n",
    "with col1:\n",
    "    duration = st.number_input(\"Record duration (seconds)\", min_value=1, max_value=10, value=RECORD_SECONDS_DEFAULT, step=1)\n",
    "    if st.button(\"üî¥ Record\"):\n",
    "        audio_path = record_audio(duration=duration, sr=SAMPLE_RATE)\n",
    "        if audio_path:\n",
    "            st.success(\"Recording saved.\")\n",
    "            st.audio(audio_path)\n",
    "            input_audio_path = audio_path\n",
    "\n",
    "with col2:\n",
    "    uploaded_file = st.file_uploader(\"Or upload a .wav file\", type=[\"wav\"])\n",
    "    if uploaded_file is not None:\n",
    "        tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "        tmp.write(uploaded_file.read())\n",
    "        tmp.flush()\n",
    "        st.success(\"File uploaded successfully.\")\n",
    "        st.audio(tmp.name)\n",
    "        input_audio_path = tmp.name\n",
    "\n",
    "# Run prediction if input is provided\n",
    "if input_audio_path:\n",
    "    predict_and_log(input_audio_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Trend graph (dynamic, uses session_state history_df)\n",
    "# ----------------------------\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"üìà Emotion trend (session history)\")\n",
    "\n",
    "def plot_trend_from_df(df, title=\"Emotion counts (recent)\"):\n",
    "    if df is None or df.empty:\n",
    "        st.info(\"No session history to plot yet. Record or upload some samples.\")\n",
    "        return\n",
    "\n",
    "    df = df.copy()\n",
    "    if \"predicted\" not in df.columns:\n",
    "        st.info(\"Session log has no 'predicted' column yet.\")\n",
    "        return\n",
    "    df[\"predicted\"] = df[\"predicted\"].astype(str)\n",
    "\n",
    "    N = 50\n",
    "    last = df.tail(N).reset_index(drop=True)\n",
    "\n",
    "    emotions = list(label_encoder.classes_)\n",
    "    counts_over_time = pd.DataFrame(0, index=range(len(last)), columns=emotions)\n",
    "\n",
    "    for i, emo in enumerate(last[\"predicted\"]):\n",
    "        if emo in emotions:\n",
    "            counts_over_time.loc[i, emo] = 1\n",
    "\n",
    "    cum_counts = counts_over_time.cumsum()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "    for emo in emotions:\n",
    "        ax.plot(cum_counts.index, cum_counts[emo], label=emo, marker=\"o\")\n",
    "    ax.set_xlabel(\"Recent session index (most recent on right)\")\n",
    "    ax.set_ylabel(\"Cumulative count\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend(loc=\"upper left\", bbox_to_anchor=(1.02, 1.0))\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig)\n",
    "\n",
    "plot_trend_from_df(st.session_state.get(\"history_df\", pd.DataFrame()), title=\"Cumulative emotion counts (last 50 sessions)\")\n",
    "\n",
    "# ----------------------------\n",
    "# Recent sessions table & controls\n",
    "# ----------------------------\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"Recent sessions\")\n",
    "\n",
    "if st.session_state.get(\"history_df\", pd.DataFrame()).empty:\n",
    "    st.info(\"No sessions logged yet.\")\n",
    "else:\n",
    "    recent = st.session_state[\"history_df\"].copy()\n",
    "    # show latest first\n",
    "    recent = recent.sort_values(\"timestamp\", ascending=False).reset_index(drop=True)\n",
    "    st.dataframe(recent.head(10))\n",
    "\n",
    "col_clear, col_export = st.columns(2)\n",
    "with col_clear:\n",
    "    if st.button(\"Clear history (delete CSV)\"):\n",
    "        st.session_state[\"history_df\"] = pd.DataFrame()\n",
    "        try:\n",
    "            if os.path.exists(SESSION_LOG):\n",
    "                os.remove(SESSION_LOG)\n",
    "            st.success(\"Session history cleared.\")\n",
    "        except Exception as e:\n",
    "            st.error(\"Failed to clear session file: \" + str(e))\n",
    "with col_export:\n",
    "    if st.button(\"Export history CSV\"):\n",
    "        if not st.session_state.get(\"history_df\", pd.DataFrame()).empty:\n",
    "            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
    "            st.session_state[\"history_df\"].to_csv(tmp.name, index=False)\n",
    "            with open(tmp.name, \"rb\") as f:\n",
    "                st.download_button(\"Download CSV\", f, file_name=\"session_log.csv\")\n",
    "        else:\n",
    "            st.info(\"No data to export.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Notes & tips\n",
    "# ----------------------------\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "---\n",
    "**Notes & tips**\n",
    "- The model expects audio sampled (or resampled) at 22050 Hz (librosa will resample automatically).\n",
    "- Recording uses the `sounddevice` library (works when running locally). For browser-based recording you can use `streamlit-webrtc`.\n",
    "- If you retrain the model to include more features, ensure `extract_features` here matches the training features exactly.\n",
    "- Requirements (suggested):\n",
    "    pip install streamlit sounddevice soundfile librosa numpy pandas scikit-learn joblib matplotlib\n",
    "- Run locally:\n",
    "    streamlit run app.py\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1651c-7f43-4aab-a9b1-4dafbfd32baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f5878-5730-4d08-b6d3-e645de487f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
