## Human Emotion Detection from Voice
# Project Overview

Human emotions are deeply expressed through voice â€” whether we're happy, sad, calm, or angry, our tone reveals it.
This project uses Machine Learning and Audio Signal Processing to automatically detect a speakerâ€™s emotional state using their voice.

âœ… Upload or record an audio file

âœ… Instantly get the detected emotion & confidence score

âœ… View emotional trends over time in a live graph

Built using Python, Librosa, Scikit-learn, and Streamlit, this application demonstrates the power of AI in understanding human emotion for real-world applications such as mental health monitoring, customer support analytics, and user-personalized systems.

#Features
Upload or record voice in real-time

Extracts advanced audio features (MFCC, Chroma, Spectral Contrast)

Predicts emotion using a trained SVM classifier

Shows confidence score of prediction

Displays a dynamic emotion trend graph based on user session history

Saves prediction logs for future analysis

# Tech Stack

Component	Technology Used

Programming	Python

ML Model	SVM (Support Vector Machine)

Audio Processing	Librosa

GUI / Web App	Streamlit

Dataset	RAVDESS Emotional Speech Dataset

# Project Structure

emotion-detection-voice/
â”‚
â”œâ”€â”€ features_mfcc_delta.csv          # Extracted features
â”œâ”€â”€ generalized_emotion_model.joblib # Trained SVM model
â”œâ”€â”€ label_encoder.pkl                # Encoded emotion labels
â”œâ”€â”€ app.py                           # Streamlit UI file
â”œâ”€â”€ train_generalized_model.ipynb    # Model training notebook
â”œâ”€â”€ README.md                        # Project documentation
â””â”€â”€ requirements.txt                 # Dependencies

# Emotion Classes

The model is trained to recognize the following emotions:

ğŸ˜Œ Calm       ğŸ™‚ Happy       ğŸ˜¢ Sad       ğŸ˜¡ Angry
ğŸ˜¨ Fearful    ğŸ¤¢ Disgust     ğŸ˜² Surprised ğŸ˜ Neutral

# Installation & Setup

ğŸ”° Step 1: Clone the Repository
git clone https://github.com/your-username/emotion-detection-voice.git

cd emotion-detection-voice

ğŸ”§ Step 2: Install Dependencies

pip install -r requirements.txt

â–¶ï¸ Step 3: Run the App

streamlit run app.py

ğŸšï¸ How It Works

User uploads or records a voice sample

Features such as MFCC and Chroma are extracted

The pre-trained SVM model predicts the emotion

The confidence score is displayed

Prediction is added to the emotion trend graph

# Sample Model Performance

Emotion	Precision	Recall	F1-Score

Angry	0.90	0.98	0.94

Happy	0.89	0.88	0.89

Calm	0.86	0.89	0.88

Overall Accuracy	0.90	-	-

Cross-Validation Accuracy: 97%

# Future Enhancements
Add real-time microphone streaming

Switch to deep learning models (CNN/LSTM) for better accuracy

Deploy as mobile/web API

Enable multi-language emotion detection


